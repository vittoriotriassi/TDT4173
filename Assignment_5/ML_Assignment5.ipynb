{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TDT4173: Machine Learning and Case-Based Reasoning - Assignment 5\n",
    "### Author: Vittorio Triassi "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of the following assignment we decided to implement every task using `scikit-learn`. The main reason is that we already had the chance to use such library by implementing a few models in the previous assignment, and that is why we thought it would be a good idea to stick with it in this case as well. It is also true that several are the libraries available to carry out the same tasks. With a better understanding of the architectures and of course of the syntax, it would have been nice to use such libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-image\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io\n",
    "from random import randint\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_examples(test_size = 0.2):\n",
    "\n",
    "    examples = np.zeros(shape = (7112, 400), dtype = int)\n",
    "    labels = np.zeros(shape = (7112), dtype = int)\n",
    "\n",
    "    i = 0\n",
    "    index = 0\n",
    "    for letter in str('abcdefghijklmnopqrstuvwxyz'):\n",
    "        for img_name in os.listdir(os.path.join('chars74k-lite', letter)):\n",
    "            path = os.path.join('chars74k-lite', letter, img_name)\n",
    "            examples[i] = np.array(skimage.io.imread(path)).flatten()\n",
    "            labels[i] = index\n",
    "            i += 1\n",
    "        index += 1\n",
    "\n",
    "    train_X, test_X, train_y, test_y = train_test_split(examples, labels, test_size = test_size, random_state = 42)\n",
    "    print(\"Training examples: \" + str(len(train_X)) + \" / Test examples: \" + str(len(test_X)))\n",
    "\n",
    "    return train_X, test_X, train_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples: 5689 / Test examples: 1423\n"
     ]
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = load_examples(test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To  carry  out  the feature  engineering part,  we  decided  to: standardize the  features and apply the principal component analysis. The main reason why we chose the folllowing tecniques is that almost all the machine learning estimators need standardized datasets.  When we talk about standardizing our dataset, we are saying nothing but removing the mean and scaling to unit variance. In our task, we used `StandardScaler` from `sklearn.preprocessing`. What we do is to center and scale each feature.  Another  reason  why  scaling  the  features  is  a  good  practice  is  that  if  a  feature  has  a variance that is way larger than the others, it might dominate the objective function ending up in an estimator not able to learn as expected.  The second tecnique used is the principal component analysis (PCA). PCA uses Singular Value Decomposition to project high dimensional data to a lower dimensional representation.  In order for PCA to work, the input has to be centered before applying the SVD.  In our task, `PCA` from `sklearn.decomposition` was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_features(train_X, test_X):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(train_X)\n",
    "\n",
    "    train_X = scaler.transform(train_X)\n",
    "    test_X = scaler.transform(test_X)\n",
    "\n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal_component_analysis(train_X, test_X, n_components = 1):\n",
    "\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(train_X)\n",
    "    pca_train = pca.transform(train_X)\n",
    "    pca_test = pca.transform(test_X) \n",
    "\n",
    "    return pca_train, pca_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X = standardize_features(train_X, test_X)\n",
    "pca_train, pca_test = principal_component_analysis(train_X, test_X, n_components = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  models  we  used  in  the  following  task  were  a  Support  Vector  Machine  (SVM) and a Random Forest.  In SVMs, we try to find a hyperplane that is able to separate two classes of the data by finding the largest margin.  SVMs have a good accuracy compared to other tecniques but are very hard to tune because they involve a lot of parameters. Random Forest is a classifier that fits a number of decision tree classifiers on sub-sets of the dataset and averages the results to improve the accuracy of the model without running into overfitting.  In our code, we used `SVC` from `sklearn.svm` and `RandomForestClassifier` from `sklearn-ensemble`.  We chose the following models because we wanted to test less trending approaches to solve an interesting problem such as image classification.  Usually, CNNs are preferred over other tecniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Between our two models, SVM performed better, achieving an accuracy around $80\\%$ on the test data. The second model, the Random Forest, performed slightly worse achieving $70\\%$. We can be quite satisfied with the first model since we did not tuned its parameters so much and still we obtained good results. As stated before, SVMs can be hard to tune and at least in our case, we have simply used the default kernel (`rbf`) and tried a few values for `gamma`. Both models were run after having performed the feature scaling. Five predictions from both classifiers are shown. As we can see, the SVM is more precise in its predictions, while the RFC gets more often confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf_SVM = svm.SVC(gamma=0.0035, probability=True)\n",
    "clf_SVM.fit(train_X, train_y)\n",
    "score_SVM = clf_SVM.score(test_X, test_y)\n",
    "prediction_SVM = clf_SVM.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.92      0.79       157\n",
      "           1       0.77      0.33      0.47        30\n",
      "           2       0.91      0.83      0.87        47\n",
      "           3       0.80      0.54      0.64        52\n",
      "           4       0.72      0.89      0.80       144\n",
      "           5       0.93      0.54      0.68        24\n",
      "           6       0.88      0.55      0.68        42\n",
      "           7       0.79      0.66      0.72        41\n",
      "           8       0.72      0.79      0.75        80\n",
      "           9       0.77      0.43      0.56        23\n",
      "          10       0.92      0.52      0.67        23\n",
      "          11       0.90      0.83      0.86        53\n",
      "          12       0.81      0.81      0.81        36\n",
      "          13       0.78      0.90      0.84       105\n",
      "          14       0.73      0.92      0.81        99\n",
      "          15       0.97      0.76      0.85        38\n",
      "          16       1.00      0.11      0.19        19\n",
      "          17       0.64      0.87      0.73       100\n",
      "          18       0.90      0.89      0.89        98\n",
      "          19       0.92      0.87      0.89        87\n",
      "          20       0.87      0.52      0.65        25\n",
      "          21       1.00      0.70      0.82        30\n",
      "          22       1.00      0.67      0.80        18\n",
      "          23       0.85      0.50      0.63        22\n",
      "          24       0.80      0.53      0.64        15\n",
      "          25       1.00      0.47      0.64        15\n",
      "\n",
      "    accuracy                           0.78      1423\n",
      "   macro avg       0.85      0.67      0.72      1423\n",
      "weighted avg       0.80      0.78      0.77      1423\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM classification report:\\n\" + str(metrics.classification_report(test_y, prediction_SVM)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_RFC = RFC(n_estimators=300)\n",
    "clf_RFC.fit(train_X, train_y)\n",
    "clf_RFC.score(test_X, test_y)\n",
    "prediction_RFC = clf_RFC.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFC classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.85      0.71       157\n",
      "           1       1.00      0.20      0.33        30\n",
      "           2       0.73      0.79      0.76        47\n",
      "           3       0.71      0.19      0.30        52\n",
      "           4       0.64      0.88      0.74       144\n",
      "           5       1.00      0.17      0.29        24\n",
      "           6       1.00      0.40      0.58        42\n",
      "           7       0.82      0.66      0.73        41\n",
      "           8       0.65      0.78      0.71        80\n",
      "           9       1.00      0.13      0.23        23\n",
      "          10       0.90      0.39      0.55        23\n",
      "          11       0.83      0.74      0.78        53\n",
      "          12       0.78      0.69      0.74        36\n",
      "          13       0.79      0.86      0.82       105\n",
      "          14       0.55      0.92      0.69        99\n",
      "          15       0.88      0.74      0.80        38\n",
      "          16       0.00      0.00      0.00        19\n",
      "          17       0.65      0.81      0.72       100\n",
      "          18       0.88      0.89      0.88        98\n",
      "          19       0.70      0.84      0.76        87\n",
      "          20       1.00      0.12      0.21        25\n",
      "          21       0.90      0.63      0.75        30\n",
      "          22       1.00      0.56      0.71        18\n",
      "          23       0.89      0.36      0.52        22\n",
      "          24       0.86      0.40      0.55        15\n",
      "          25       0.75      0.20      0.32        15\n",
      "\n",
      "    accuracy                           0.70      1423\n",
      "   macro avg       0.79      0.55      0.58      1423\n",
      "weighted avg       0.74      0.70      0.67      1423\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\notebook\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"RFC classification report:\\n\" + str(metrics.classification_report(test_y, prediction_RFC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random predictions for SVM\n",
      "Target: 6 / Prediction: [6]\n",
      "Target: 6 / Prediction: [14]\n",
      "Target: 13 / Prediction: [13]\n",
      "Target: 3 / Prediction: [3]\n",
      "Target: 21 / Prediction: [21]\n",
      "\n",
      "Random predictions for RFC\n",
      "Target: 13 / Prediction: [13]\n",
      "Target: 25 / Prediction: [4]\n",
      "Target: 24 / Prediction: [24]\n",
      "Target: 21 / Prediction: [21]\n",
      "Target: 0 / Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random predictions for SVM\")\n",
    "for i in range(5):\n",
    "    r = randint(0, len(test_y))\n",
    "    print(\"Target: \" + str(test_y[r]) + \" / Prediction: \" + str(clf_SVM.predict(test_X[r].reshape(1, -1))))\n",
    "    \n",
    "print(\"\\nRandom predictions for RFC\")\n",
    "for i in range(5):\n",
    "    r = randint(0, len(test_y))\n",
    "    print(\"Target: \" + str(test_y[r]) + \" / Prediction: \" + str(clf_RFC.predict(test_X[r].reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several are the improvements that are possible when trying to address an object detection task. In our case, two different images were provided. In the first image, even without specific modifications, it is possible to detect the characters. On the other hand in the second one, we notice that a few characters are rotated. Unless our detector is implemented in such a way that considers also other rotations, it is not able to detect such angles. Other possible improvements might be related to the scale of the objects we want to detect. For instance, in our detector we set a window size of $20 \\times 20$ pixels. If we are trying to detect something on a different scale, it will be a problem and our detector will not be as effective as it is on the aforementioned scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#!pip install opencv-python\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_1 = cv2.imread('./detection-images/detection-1.jpg')\n",
    "image_2 = cv2.imread('./detection-images/detection-2.jpg')\n",
    "\n",
    "#cv2.imshow('image', image_1)\n",
    "tmp = image_1\n",
    "stepSize = 1\n",
    "(width, height) = (20, 20)\n",
    "for x in range(0, image_1.shape[1] - width , stepSize):\n",
    "    for y in range(0, image_1.shape[0] - height, stepSize):\n",
    "        window = image_1[x:x + width, y:y + height, :]\n",
    "        \n",
    "# now we use the classifier previously defined (SVM)\n",
    "# and detect letters if there are any\n",
    "\n",
    "    # draw rectangle on image\n",
    "    cv2.rectangle(tmp, (x, y), (x + width, y + height), (255, 0, 0), 2)\n",
    "    plt.imshow(np.array(tmp).astype('uint8'))\n",
    "    \n",
    "# show the recognized letters\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
